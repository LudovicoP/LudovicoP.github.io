UNIVERSITÀ COMMERCIALE LUIGI BOCCONI

Corso di Laurea Triennale / Bachelor of Science
in Economics, Management and Computer Science

BAYESIAN TECHNIQUES FOR RACING DYNAMICS:
MONZA 2023 F1 GP APPLIED CASE

Relatore / Advisor:
Prof. Omiros Papaspiliopoulos

Tesi di Laurea Triennale di /
Bachelor of Science thesis by:
LUDOVICO AMEDEO PANARIELLO
matricola n. / student ID no. 3192212

Anno Accademico / Academic Year 2024-2025

To my family — for giving me the space to figure things out on my own.
To my brothers — for teaching me with their courage not to settle.
To Giulia — for supporting me with love, patience, and understanding. To our future
together.
To my friends and classmates — for turning pressure into motivation and for making
even the hardest days part of what I will carry with me forever.
To my supervisor, Om — for his openness to share with me choices about my future; and
to Max, for turning a passion into a thesis topic.
To myself — for keeping the enthusiasm alive and for pushing forward, even when it
would have been easier to give up.
To every struggle — for teaching me more than any win ever could.

Just as Formula 1 forces drivers to redefine limits, so has my experience at Bocconi
pushed me further than I thought possible.
This is where I start again, determined to pursue new paths.

Alla mia famiglia — per avermi lasciato il tempo e lo spazio per trovare la mia strada da
solo.
Ai miei fratelli — perché con il loro coraggio mi hanno insegnato a non accontentarmi.
A Giulia — per avermi sostenuto con Amore, pazienza e comprensione. Al nostro futuro
insieme.
Agli amici e ai compagni di corso — perché insieme la pressione è diventata stimolo, e
anche le giornate più diﬀicili sono entrate a far parte di un capitolo che porterò con me
per sempre.
Al mio relatore, Om — per la sua disponibilità a condividere con me scelte del mio
futuro; e a Max per aver trasformato una passione in un tema di tesi.
A me stesso — per aver tenuto vivo l’entusiasmo e aver proseguito, anche quando
sarebbe stato più semplice fermarsi.
Alle diﬀicoltà — perché mi hanno forgiato più di qualsiasi traguardo raggiunto.

Così come la Formula 1 porta i piloti a ridefinire i propri limiti, anche il percorso in
Bocconi mi ha spinto più lontano di quanto immaginassi.
È da qui che riparto, deciso a percorrere nuove strade.

Contents
1 Introduction and Motivation

1

1.1

Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.2

Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.3

Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

1.4

Theoretical Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

2 Bayesian Framework
2.1

2.2

2.3

8

Philosophical and Mathematical Foundations of Bayesian Inference . . . .

8

2.1.1

Prior Distributions in Practice

. . . . . . . . . . . . . . . . . . . .

9

2.1.2

Likelihood Functions for Regression . . . . . . . . . . . . . . . . . .

9

2.1.3

Posterior and Predictive Inference . . . . . . . . . . . . . . . . . . . 10

2.1.4

Model Comparison and Adequacy . . . . . . . . . . . . . . . . . . . 10

Bayesian Computation and MCMC . . . . . . . . . . . . . . . . . . . . . . 12
2.2.1

Markov Chains and Ergodicity . . . . . . . . . . . . . . . . . . . . 12

2.2.2

Metropolis–Hastings Algorithm . . . . . . . . . . . . . . . . . . . . 12

Hamiltonian Monte Carlo (HMC) . . . . . . . . . . . . . . . . . . . . . . . 13
2.3.1

Hamiltonian Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . 13

2.3.2

Leapfrog Integrator and Acceptance Step . . . . . . . . . . . . . . . 14

2.3.3

Benefits and Practical Use . . . . . . . . . . . . . . . . . . . . . . . 14

2.3.4

Model Checking and Evaluation . . . . . . . . . . . . . . . . . . . . 15

3 Linear Gaussian Modeling

16

3.1

Model Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

3.2

Hierarchical Priors and Latent Structure . . . . . . . . . . . . . . . . . . . 17

3.3

Inference and Diagnostics . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.4

Results and Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.4.1

Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . 19

3.4.2

Latent Tire Degradation . . . . . . . . . . . . . . . . . . . . . . . . 20

3.4.3

Model Diagnostics . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

i

3.5

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

4 Bayesian Spline-Based Modeling

24

4.1

Mathematical Foundations of Spline Smoothing . . . . . . . . . . . . . . . 24

4.2

Bayesian Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

4.3

State-Space Extension with Spline Drift . . . . . . . . . . . . . . . . . . . 25
4.3.1

Model Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

4.4

Stan Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

4.5

Application to F1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

4.6

Diagnostics and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

4.7

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

5 Conclusion and Future Work

31

5.1

Comparative Analysis of Tire Degradation Models . . . . . . . . . . . . . . 31

5.2

Future Research Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

5.3

5.2.1

Gaussian Processes for Enhanced Degradation Modeling . . . . . . 32

5.2.2

Particle Filters (Sequential Monte Carlo) for Online Inference . . . 33

5.2.3

Other Promising Directions . . . . . . . . . . . . . . . . . . . . . . 34

Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

ii

1.

Introduction and Motivation

1.1

Purpose

In modern Formula 1, managing tire degradation is crucial for race performance. The actual degradation—the compound’s loss of properties affecting lap times—is unobservable
during a race, unlike indicators such as surface temperature or internal pressure.
Estimating this degradation is challenging due to multiple interacting factors, including track conditions, driving style, tire compound, and stint length. The degradation
state is a latent, evolving quantity that must be inferred from noisy and indirect data,
framing this as an inherently statistical problem. The significance of tire management in
Formula 1 is becoming increasingly central to performance, and its complexity often leads
to it being described as a “black art.” One clear example of this sentiment comes from
McLaren’s Team Principal, Andrea Stella, who, while his team is currently dominating
the championship, praised his engineering department for mastering one of the sport’s
most elusive challenges: “I just want to take the opportunity to praise the work that has
been done by the engineers at McLaren … and then master one of the matters that still
in Formula 1 looks like it’s a little bit of a black art, which is dealing with tyres” [14].
This thesis aims to develop and evaluate a statistically principled framework for estimating in-race tire degradation, seeking to shed light on this “black art” through rigorous
statistical modeling. The focus is on methods that are both interpretable, allowing for
insights into the degradation process, and offer potential for online adaptability in a race
context.
A key aspect of this work involves structuring data handling and preprocessing to
effectively train and validate the proposed models—specifically, the linear Gaussian and
natural spline models detailed in Chapters 3 and 4. This ensures that the models can
learn meaningful tire degradation patterns from observable race data.

1

1.2

Methods

The modeling approach is grounded in the theory of Bayesian state-space models [5]. We
define a latent degradation state θt ∈ R that evolves over time according to a stochastic
process, and we specify a measurement equation that relates θt to observable telemetry
data, such as lap times or sector deltas. The general formulation is:
θt = f (θt−1 ) + ηt ,
yt = g(θt ) + ϵt ,
where ηt ∼ N (0, τ 2 ) is process noise and ϵt ∼ N (0, σ 2 ) is observation noise. The functions f and g determine the dynamic and measurement models, respectively. Depending
on the assumptions made on these functions, the resulting inference techniques vary in
complexity and tractability.
Our methodological journey commences with a foundational linear Gaussian model,
where f (θt−1 ) = θt−1 + β and g(θt ) = θt . This initial framework, often solvable with
techniques like the Kalman filter [10], provides a robust baseline and allows for the clear
interpretation of degradation as a linear trend. It serves as an essential first step in
understanding the basic dynamics and the impact of key covariates.
To capture more nuanced and realistic non-linear degradation patterns, which are
frequently observed in tire performance data, we then progress to semi-parametric techniques. Specifically by employing Bayesian natural splines. This approach models the
degradation trajectory with significant flexibility by representing it as a linear combination of natural spline basis functions (a specific type of B-spline basis, constrained to be
linear beyond the boundary knots, and generated in R using ‘ns()‘). The smoothness of
the resulting curve is primarily achieved through the Bayesian prior placed on the spline
coeﬀicients. This allows the model to adapt to complex shapes in the degradation profile,
such as initial conditioning phases, periods of stable wear, and accelerated degradation
towards the end of a tire’s life, without imposing rigid parametric assumptions. The
Bayesian formulation provides a natural way to quantify uncertainty in the estimated
non-linear degradation function.
The core analytical framework in this thesis relies on two main approaches: linear

2

Gaussian models and Bayesian natural spline models. Each modeling approach is evaluated in terms of its predictive performance, ability to capture known phenomena, uncertainty quantification, and computational considerations. The goal is not only to estimate the latent state θt accurately but also to provide credible intervals that reflect
the epistemic and aleatoric uncertainty inherent to the problem. While more advanced
techniques such as Gaussian Processes and Particle Filters offer promising avenues for
future research, particularly for enhanced non-parametric modeling and real-time online
inference respectively, for now this thesis concentrates on establishing a solid bayesian
modeling foundation.

1.3

Data

The empirical illustrations in this thesis are grounded in Formula 1 telemetry and timing
data, which is programmatically accessed and processed. For this purpose, the FastF1
Python library [15] serves as a crucial tool. FastF1 is an unoﬀicial, open-source package
providing comprehensive access to F1 data, encompassing live timing information, historical race data, car telemetry, and session results. It interfaces with the Ergast Developer
API and other data sources, parsing raw information into structured formats suitable for
analysis. The capabilities of FastF1 leveraged in this work include its functions for loading
lap-by-lap data, accessing detailed telemetry channels (e.g., speed, RPM, gear, throttle,
brake), and retrieving information about tire compounds, stint lengths, and pit stops for
individual drivers across various race events.
The models developed herein are designed to operate on typical data structures obtainable from such sources. The primary types of data relevant to the modeling of tire
degradation, and their conceptual roles within the statistical frameworks presented, include:
• Lap-Level Performance Metrics:
– Lap Time: This scalar value, representing the total time taken to complete a
lap, serves as the primary response variable in our models. The objective is
to predict and understand the systematic changes in lap time as a function of
tire wear and other factors.

3

– Tire Compound: A categorical variable (e.g., Soft, Medium, Hard) indicating
the specific tire specification used. This is a critical predictor, as different
compounds exhibit distinct baseline performance and degradation characteristics. Models incorporate compound-specific intercepts or coeﬀicients to capture
these variations, as seen in both the linear Gaussian (Chapter 3) and natural
spline model (Chapter 4) formulations.
– Lap Number: While primarily an ordinal counter, lap number can implicitly
capture effects like track evolution or changing fuel loads if these are not explicitly modeled as separate covariates. It also helps sequence the observations
correctly.
– Pit Flags: Boolean indicators for pit-in and pit-out laps are crucial for data
segmentation, specifically for identifying the start and end of a stint and for
excluding laps that are not representative of continuous racing performance
under normal conditions.
• Contextual and Derived Variables:
– Driver Identification: A categorical variable used to account for systematic
variations in performance that can be attributed to individual driver characteristics (e.g., driving style, inherent pace). Models may include driver-specific
random or fixed effects, as implemented in the provided R scripts for both
linear and spline approaches.
– Stint Identifier: A grouping variable that uniquely identifies a sequence of consecutive laps run on a single set of tires by a specific driver. This is fundamental
for calculating tire age accurately.
– Tire Age (TireLife): This is a key numerical predictor, derived by counting
the number of laps a specific tire set has completed within its current stint. It
is the primary variable through which tire degradation is modeled.
∗ In linear Gaussian models (Chapter 3), TireLife enters as a direct predictor with interactions with TireCompound, to estimate a rate of lap time increase per lap of tire use. The R code for the linear model (linear_code.R)
exemplifies this by using TireLife as a covariate.

4

∗ In semi-parametric spline models (Chapter 4), TireLife serves as the independent variable for the basis functions (e.g., B-splines). The model
then estimates coeﬀicients for these basis functions, allowing for a flexible, non-linear relationship between tire age and lap time degradation.
The Stan code (splines_model.stan) and its accompanying R script
(splines_code.R) demonstrate this by constructing a B-spline basis matrix from TireLife values, which then forms part of the design matrix for
predicting lap times.
• Telemetry Data (Secondary Focus for this Thesis): While the primary models in this thesis focus on lap-level data for broader applicability, more granular
telemetry (e.g., speed, distance, RPM, gear, throttle, brake, DRS status) sampled
at high frequency can provide richer information for more detailed or alternative
modeling approaches, such as those involving Gaussian Processes or Particle Filters
mentioned as future avenues.
• Session and Environmental Information: Contextual data such as the event
name, session type (Practice, Qualifying, Race), track status (e.g., safety car periods), and weather conditions (ambient temperature, track temperature) are important covariates that can influence tire behavior. While often considered in comprehensive analyses, they are treated as controlled or averaged out in the primary
models of this thesis for simplicity, to maintain focus on the core degradation dynamics influenced by tire age and compound.
Although this thesis is primarily theoretical, focusing on the development and Bayesian
treatment of statistical models for tire degradation, the data serves an illustrative purpose. It allows for the demonstration of model application, the exploration of inferential
outcomes, and the comparison of different modeling strategies using realistic scenarios. It
is important to note that the data used in the following chapters is drawn from the 2023
Monza Grand Prix, specifically the race stints of drivers Leclerc, Verstappen, Gasly, and
Norris.

5

1.4

Theoretical Framework

The theoretical framework of Bayesian statistics provides a robust foundation for the
objective. The work by [9] offers a comprehensive and practically oriented overview of
Bayesian methods, which has guided the modeling choices adopted in this thesis. Bayesian
inference allows for the incorporation of prior knowledge, the quantification of uncertainty
in a principled manner, and the flexible modeling of complex dependencies. Core concepts
such as prior distributions, likelihood functions, and posterior distributions are central to
this approach, as detailed by [13].
At the heart of Bayesian inference is the updating of beliefs in light of new evidence,
formalized through Bayes’ theorem. In the context of this thesis, Bayesian methods are
particularly suited for modeling tire degradation due to their ability to handle complex,
non-linear relationships and to update predictions as more data becomes available during
a race. The incorporation of prior distributions reflects any existing knowledge about tire
degradation patterns, which can be updated with race data to yield posterior distributions
representing updated beliefs about the degradation state.
The flexibility of Bayesian models allows for the accommodation of various sources of
uncertainty, including the inherent variability in tire performance, measurement errors in
lap times, and the stochastic nature of tire degradation processes. By employing hierarchical modeling approaches, the models can also account for variations across different
races, drivers, and tire compounds, capturing the multi-level structure of the data.
Computationally, the implementation of Bayesian models in this thesis utilizes
Markov-Chain Monte Carlo (MCMC) methods for posterior inference, specifically the
No-U-Turn Sampler (NUTS) algorithm, as implemented in the Stan modeling language
[2]. This approach enables the fitting of complex models with high-dimensional parameter
spaces, typical in Bayesian hierarchical modeling. The use of informative priors, based
on historical data and expert knowledge, further aids in stabilizing the estimates and
improving the convergence of the MCMC algorithms.
In summary, the theoretical underpinnings of Bayesian statistics, coupled with its
computational implementation through advanced MCMC methods, provide a powerful
toolkit for tackling the challenging problem of tire degradation modeling in Formula 1.
The following chapters will detail the specific modeling approaches and their applications

6

to real race data, illustrating the practical utility of this theoretical framework.

7

2.

Bayesian Framework

This chapter establishes the Bayesian modeling foundations essential for studying tire
degradation in Formula 1. It covers the Bayesian interpretation of probability, posterior
inference, predictive distributions, and computational methods, with a focus on Hamiltonian Monte Carlo (HMC). This foundational toolkit underpins the analytical approach
of the subsequent modeling chapters.

2.1

Philosophical and Mathematical Foundations of
Bayesian Inference

In Bayesian statistics, probability is interpreted as a degree of belief or uncertainty. This
framework allows updating beliefs about a parameter θ after observing data y by combining prior beliefs with observed information. Bayes’ theorem, derived from conditional
probability, is central:
P (A | B) =

P (A ∩ B)
.
P (B)

(2.1)

This extends to statistical modeling with continuous parameters. For an unknown parameter θ ∈ Θ and observed data y, Bayes’ theorem is:
p(θ | y) =

p(y | θ)p(θ)
,
p(y)

(2.2)

where:
• p(θ) is the prior distribution, representing beliefs about θ before seeing data;
• p(y | θ) is the likelihood, modeling how likely the data is given θ;
• p(θ | y) is the posterior distribution, our updated belief after seeing y;
• p(y) =

∫

p(y | θ)p(θ) dθ is the marginal likelihood, ensuring normalization.

This formulation of Bayes’ theorem is the cornerstone of Bayesian learning, providing
a robust mechanism to update beliefs and quantify uncertainty in the presence of data.

8

2.1.1

Prior Distributions in Practice

The choice of prior distribution, p(θ), is a defining characteristic of Bayesian inference.
Priors can range from being highly informative, encoding specific expert knowledge or
results from previous studies, to weakly informative or non-informative, intended to let
the data speak for itself as much as possible. In the context of regression models, such
as the linear and natural spline models explored in Chapters 3 and 4, common choices
include:
• Gaussian (Normal) priors for regression coeﬀicients (e.g., βj ). These are often
centered at zero, N (0, σβ2 ), implying that large deviations from zero are less likely a
priori. The variance σβ2 controls the degree of regularization: smaller variances lead
to stronger shrinkage of coeﬀicients towards zero.
• Half-Cauchy or Inverse-Gamma priors for variance parameters (e.g., σ 2 , the
residual variance, or variances of random effects). These priors are defined on
positive real numbers and are often chosen for their flexibility and good frequentist
properties in some settings. For example, a Half-Cauchy prior is often recommended
as a weakly informative prior for scale parameters.
Careful consideration of priors is important, as they can influence the posterior, especially
with limited data. Sensitivity analysis, exploring how posterior inferences change under
different prior specifications, is a good practice.

2.1.2

Likelihood Functions for Regression

The likelihood function, p(y | θ), quantifies how probable the observed data y are for a
given set of parameters θ. For models aiming to predict a continuous outcome, such as
the tire degradation metrics in this thesis, a common choice is the Gaussian (Normal)
likelihood. If yi is an individual observation and µi is its predicted mean from the model
(e.g., µi = xiT β in a linear model), the likelihood for yi is often assumed to be:
(

)

1
(yi − µi (θ))2
p(yi | θ, σ ) = N (yi | µi (θ), σ ) = √
exp −
,
2σ 2
2πσ 2
2

2

(2.3)

where σ 2 is the observation variance. The full likelihood for N independent observations
is then the product

∏N

2
i=1 p(yi | θ, σ ).

This choice implies that the errors (yi − µi (θ)) are
9

normally distributed.

2.1.3

Posterior and Predictive Inference

Once we have computed the posterior distribution p(θ | y), we can summarize it in various
ways depending on the inferential goal. Common summaries include:
• The posterior mean E[θ | y], which minimizes squared error loss.
• The posterior mode arg maxθ p(θ | y), useful when the posterior is unimodal.
• Credible intervals, which provide intervals [a, b] such that P(a < θ < b | y) =
1 − α.
A key strength of Bayesian inference is its natural and coherent approach to prediction.
Rather than conditioning on a point estimate of θ, Bayesian predictions account for our
full uncertainty about θ. The posterior predictive distribution for a new data point
ỹ is:
p(ỹ | y) =

∫

p(ỹ | θ)p(θ | y) dθ.

(2.4)

This integral averages the likelihood of future data over the posterior distribution of the
parameters, ensuring that all sources of uncertainty are integrated into predictions. The
posterior predictive distribution is not only crucial for making predictions about future,
unobserved data but also plays a vital role in posterior predictive checking. This
involves generating replicated datasets ỹ rep from p(ỹ | y) and comparing them to the
observed dataset y. If the model is a good fit to the data, the replicated datasets should
look similar to the observed data in terms of relevant summary statistics or graphical
features. Discrepancies can highlight aspects where the model fails to capture the data
generating process, guiding model refinement.

2.1.4

Model Comparison and Adequacy

In practice, multiple candidate models may be proposed to explain a given phenomenon.
Bayesian statistics offers a principled framework for comparing these models and assessing
their adequacy.

10

Information Criteria
For complex models where the marginal likelihood p(y) is diﬀicult to compute directly,
information criteria provide a practical way to estimate out-of-sample predictive accuracy.
Two widely used criteria are:
• Watanabe-Akaike Information Criterion (WAIC): WAIC is a more fully
Bayesian approach to estimating out-of-sample expectation and is asymptotically
equal to Bayesian cross-validation. It is calculated as:

WAIC = −2 (lppd − pWAIC ) ,

(2.5)

where lppd is the log pointwise predictive density, and pWAIC is an effective number
of parameters penalty.
• Leave-One-Out Cross-Validation (LOO-CV): LOO-CV estimates the predictive accuracy by iteratively holding out one data point, fitting the model to the
remaining data, and predicting the held-out point. While computationally intensive if done naively, approximations like Pareto Smoothed Importance Sampling
LOO (PSIS-LOO) make it feasible.
Lower values of WAIC or LOO-CV generally indicate better expected predictive performance. These criteria will be employed in Chapter 5 to evaluate the relative performance
of the linear and spline models for tire degradation.
Graphical Posterior Predictive Checks
Beyond numerical summaries, graphical checks are invaluable. As mentioned earlier, by
simulating replicated data ỹ rep from the posterior predictive distribution, we can compare various aspects of ỹ rep to the observed data y. For instance, one might compare
histograms, means, variances, or specific quantiles. If the model captures the data’s
characteristics well, these simulated summaries should be consistent with those from the
observed data. Such checks provide qualitative insights into model fit and potential areas
of mis-specification.

11

2.2

Bayesian Computation and MCMC

In simple models, the posterior distribution p(θ | y) may have a closed-form solution. However, for most realistic models — particularly hierarchical, non-linear, or high-dimensional
ones — the posterior must be approximated using numerical methods. The most common
class of such methods is Markov Chain Monte Carlo (MCMC), which generates samples from the posterior by simulating a Markov chain that has p(θ | y) as its stationary
distribution.

2.2.1

Markov Chains and Ergodicity

A Markov chain is a sequence of random variables {θ(t) }∞
t=1 with the property that the
future depends only on the present, not on the past:
P(θ(t+1) ∈ A | θ(t) , . . . , θ(0) ) = P(θ(t+1) ∈ A | θ(t) ).

(2.6)

The chain evolves according to a transition kernel K(θ′ | θ), which specifies the
probability of moving from state θ to θ′ . A distribution π is stationary for K if:
π(θ′ ) =

∫

K(θ′ | θ)π(θ) dθ.

(2.7)

A Markov chain is ergodic if, regardless of the starting value, the distribution of θ(t)
converges to π as t → ∞. The ergodic theorem guarantees that empirical averages
converge to posterior expectations:
T
1∑
f (θ(t) ) → Eπ [f (θ)] as T → ∞.
T t=1

(2.8)

This theorem underpins the practice of approximating posterior expectations by averaging
functions of the MCMC samples.

2.2.2

Metropolis–Hastings Algorithm

The most basic and widely used MCMC algorithm is Metropolis–Hastings. Given a
current state θ, we propose a new state θ′ from a proposal distribution q(θ′ | θ) and

12

accept it with probability:
(

)

p(θ′ )q(θ | θ′ )
α(θ, θ ) = min 1,
.
p(θ)q(θ′ | θ)
′

(2.9)

If the proposal is accepted, we set θ(t+1) = θ′ ; otherwise, we retain the current state. Under
mild conditions, this procedure generates a Markov chain whose stationary distribution
is the desired posterior.
While broadly applicable, the Metropolis–Hastings algorithm can be ineﬀicient in highdimensional spaces. The random walk behavior often leads to slow mixing and high
autocorrelation. This motivates more sophisticated methods such as Hamiltonian Monte
Carlo.

2.3

Hamiltonian Monte Carlo (HMC)

Hamiltonian Monte Carlo is a gradient-based MCMC algorithm that reduces random
walk behavior by introducing auxiliary momentum variables and simulating deterministic
dynamics through parameter space. It achieves more eﬀicient exploration by proposing
distant moves with high acceptance probability.

2.3.1

Hamiltonian Dynamics

We begin by augmenting the parameter space θ ∈ Rd with a momentum variable ρ ∈ Rd .
We define a joint distribution:
p(θ, ρ) = p(θ)p(ρ),

(2.10)

where p(ρ) = N (0, M ) for some positive definite mass matrix M . The joint density defines
a Hamiltonian function:
H(θ, ρ) = U (θ) + K(ρ),

(2.11)

where U (θ) = − log p(θ) is the potential energy, and K(ρ) = 12 ρT M −1 ρ is the kinetic
energy.

13

The dynamics of the system are governed by Hamilton’s equations:
dθ
= ∇ρ H = M −1 ρ,
dt
dρ
= −∇θ H = −∇θ U (θ).
dt

(2.12)
(2.13)

These equations describe a trajectory through (θ, ρ) space that preserves the total
energy H(θ, ρ). If we could simulate this trajectory exactly, we could use it to propose
new states with probability one. In practice, we simulate it approximately using the
leapfrog method.

2.3.2

Leapfrog Integrator and Acceptance Step

The leapfrog integrator is a time-reversible and volume-preserving method that approximates the Hamiltonian dynamics in three steps:
1. Half-step momentum update: ρ ← ρ − 2ϵ ∇θ U (θ)
2. Full-step position update: θ ← θ + ϵM −1 ρ
3. Half-step momentum update: ρ ← ρ − 2ϵ ∇θ U (θ)
In this context, the symbol ← denotes computational assignment, where the value on
the right-hand side is computed and then used to update the variable on the left-hand
side. This is a common notation in algorithmic descriptions to distinguish from a strict
mathematical equality.
After L leapfrog steps of size ϵ, we obtain a proposal (θ∗ , ρ∗ ). This is accepted with
probability:
min (1, exp [H(θ, ρ) − H(θ∗ , ρ∗ )]) .

(2.14)

If the leapfrog integration were exact, the Hamiltonian would be conserved and the proposal always accepted. In practice, small integration errors are corrected by the Metropolis
step.

2.3.3

Benefits and Practical Use

HMC is particularly effective for models with continuous parameters and differentiable
log-posteriors. It allows for larger, informed moves in parameter space and tends to exhibit
14

lower autocorrelation than random walk Metropolis. However, its performance depends
on tuning parameters such as the step size ϵ, number of steps L, and the mass matrix
M . The No-U-Turn Sampler (NUTS) is an adaptive variant that removes the need to
manually set L and improves robustness.
In this thesis, HMC is the main computational tool used to sample from the posterior distributions of models of tire degradation, including those based on latent variable
dynamics. Its use enables precise inference in complex models where traditional methods
would be ineﬀicient.

2.3.4

Model Checking and Evaluation

A crucial aspect of the Bayesian workflow is model checking, which involves assessing the
fit of the model to the data and evaluating its predictive performance. This can be done
through several techniques:
• Posterior Predictive Checks (PPCs): PPCs involve simulating replicated data
from the posterior predictive distribution and comparing these simulations to the
observed data. Discrepancies can indicate model misfit. Graphical checks, such
as comparing histograms or density plots of observed versus replicated data, are
common [9].
• Information Criteria: Metrics like the Watanabe-Akaike Information Criterion
(WAIC) or the Leave-One-Out Cross-Validation (LOO-CV) provide estimates of a
model’s out-of-sample predictive accuracy, penalizing for model complexity. These
are useful for comparing different models [16].
• Sensitivity Analysis: This involves examining how sensitive the posterior inferences are to changes in prior specifications or likelihood assumptions. Robust models
should exhibit minimal sensitivity to reasonable variations in these components.
These methods collectively help in validating the model, understanding its limitations,
and ensuring that the conclusions drawn are well-supported by the data. The process of
building, fitting, and assessing model fit is iterative, often leading to model refinement.

15

3.

Linear Gaussian Modeling

This chapter presents the first applied model for investigating Formula 1 tire degradation:
a Bayesian latent variable model. It captures degradation evolution per stint, accounting
for tire compound and driver effects, using a dynamic state-space structure. This allows
differentiation of degradation patterns by compound while considering driver performance.

3.1

Model Specification

We model the standardized observed lap time ynstd at each lap n = 1, ..., N as
ynstd ∼ N (µdriver[n] + βcompound[n] + θnstd , σ 2 ),

(3.1)

where ynstd = (yn − ȳ)/sy is the lap time yn standardized using the overall mean ȳ and
standard deviation sy . Consequently, all mean and degradation parameters are on this
standardized scale.
• µdriver[n] is the driver-specific baseline performance (standardized).
• βcompound[n] is the additive adjustment for the compound in use (standardized). For
identifiability, the effect of one compound (e.g., HARD) is fixed to zero.
• θnstd is a latent variable that represents cumulative tire degradation up to lap n
(standardized).
• σ is the observation noise.
The model accommodates data from multiple drivers, various tire compounds, and numerous stints (defined as continuous sequences of laps on a given compound without pit
stops). We denote the total number of drivers by D, stints by S, and tire compounds by
C.

16

3.2

Hierarchical Priors and Latent Structure

We adopt hierarchical priors for driver baselines µd (represented as mu_driver in Stan,
derived from mu_0 and z_mu_driver).
These are defined as follows.
µ0 ∼ N (0, 1)
σµ ∼ HalfNormal(0, 0.5)
zµ,d ∼ N (0, 1) for d = 1, . . . , D
µd = µ0 + σµ zµ,d
We also introduce compound-specific adjustments βc (represented as beta_comp in
Stan, derived from sigma_comp and z_beta, with one compound fixed to 0).
Their definitions are as follows.
σcomp ∼ HalfNormal(0, 0.5)
zβ,c ∼ N (0, 1) for c = 1, . . . , C − 1
β1 = 0
βc = σcomp zβ,c

for c = 2, . . . , C

Central to our model is the latent degradation process, θnstd , which evolves over laps.
It resets to zero at the commencement of each new stint (i.e., if resetn = 1 in the data,
where n is the lap index) and also for the very first lap overall (n = 1). For subsequent
laps within a stint (n > 1 and resetn = 0), its evolution is defined as:
std
+ driftn + ηn ,
θnstd = θn−1

where ηn ∼ N (0, τ 2 )

(3.2)

The term τ (Stan: tau) captures the scale of the random walk noise and is given a
HalfNormal(0, 0.2) prior. The systematic degradation per lap, driftn , is given by:
driftn = δdriver[n] + δcompound[n]

(3.3)

Here, δdriver[n] represents the driver-specific component of the drift, and δcompound[n] represents the compound-specific component. The driver-specific drift includes a global mean

17

drift µδ , whereas the compound-specific drift is modeled as deviations around zero. This
formulation assumes that the primary, consistent positive drift (degradation) is captured
by µδ , while compound effects modulate this around a net-zero average, after accounting
for the main driver effect. The specific definitions are:

µδ ∼ N (0, 0.2)
σδ,driver ∼ HalfNormal(0, 0.2)
zδ,driver[d] ∼ N (0, 1) for d = 1, . . . , D
δdriver[d] = µδ + σδ,driver · zδ,driver[d]
The compound-specific degradation components δc (Stan: delta_compound) are modeled
similarly but without a shared mean µδ :
σδ,compound ∼ HalfNormal(0, 0.2)
zδ,compound[c] ∼ N (0, 1) for c = 1, . . . , C
δcompound[c] = σδ,compound · zδ,compound[c]
It’s important to note that priors for positively constrained scale parameters (like σµ ,
σcomp , σδ,driver , σδ,compound , τ ) are specified conceptually as HalfNormal. In the Stan implementation, these are achieved by declaring the parameter with a lower bound of 0
(e.g., real<lower=0> sigma_param) and assigning a normal(0, scale) prior, which effectively uses the positive half of the normal distribution.
The priors for the remaining scale parameters are specified as:
σ ∼ HalfNormal(0, 0.5)
τ ∼ HalfNormal(0, 0.2)
The standardized error terms zη,n−1 for the process noise are zη,n−1 ∼ N (0, 1), so that
ηn−1 = τ zη,n−1 .
This formulation replaces the previous description of δs and δ̄c . The degradation
increment is now a sum of driver and compound effects, each with its own hierarchical
structure.

18

3.3

Inference and Diagnostics

The model parameters were estimated using Hamiltonian Monte Carlo (HMC) as implemented in Stan, the details of which are described in Chapter 2. We employed four chains,
each with a substantial number of warmup and sampling iterations (4000 warmup and
8000 sampling iterations per chain). Convergence was assessed by ensuring R̂ statistics
were below 1.05 and effective sample sizes (ESS) were adequate (e.g., > 400) for key
parameters, as discussed in Chapter 2.
Posterior predictive checks (PPCs), also introduced in Chapter 2, are crucial for assessing model fit. As shown in Figure 3.5, we compare the distribution of observed lap
times against the distributions of replicated lap times generated from the fitted model.
Good correspondence suggests the model captures the essential features of the data.
Further diagnostics include examining the residuals (yn − E[yn |data]) for any systematic patterns.

3.4

Results and Interpretation

This section presents the key findings from the Bayesian linear model. We discuss the
estimated parameters, the inferred latent tire degradation, and the model’s diagnostic
checks.

3.4.1

Parameter Estimates

The posterior distributions of the key model parameters provide insights into driver baselines, compound effects, and degradation dynamics. Figure 3.1 displays a forest plot
summarizing the 95% credible intervals for a selection of these parameters, including the
overall intercept (µ0 ), standard deviations of hierarchical effects (e.g., σµ , σcomp ), and key
degradation-related terms.
This allows for a quantitative assessment of the magnitude and uncertainty associated
with each component of the model. The hierarchical structure enables robust estimation
by pooling information across drivers and compounds, as discussed in Chapter 2.

19

3.4.2

Latent Tire Degradation

A core output of the model is the estimated latent cumulative tire degradation, θnstd ,
for each lap. Figure 3.2 illustrates the posterior mean and 95% credible intervals for
the cumulative degradation trajectories, potentially averaged or shown for representative
stints.
This visualization is crucial for understanding the model’s ability to capture the unobserved wear process and its impact on lap times.

3.4.3

Model Diagnostics

Thorough diagnostic checks were performed to ensure the reliability of the MCMC simulations and the adequacy of the model fit.
MCMC Convergence
As mentioned in Section 3.3, convergence was primarily assessed using R̂ statistics and Effective Sample Sizes (ESS). Visual diagnostics further support these numerical summaries.
Figure 3.3 presents trace plots for key parameters, showing well-mixed chains that have
converged to a stable posterior distribution. Correspondingly, Figure 3.4 displays the
posterior density estimates from different chains, which should largely overlap.
Posterior Predictive Checks
Posterior predictive checks (PPCs) were used to evaluate how well the model captures
the observed data distribution, as introduced in Chapter 2. Figure 3.5 compares the
density of the observed lap times (y) with the densities of multiple replicated datasets
(y rep ) generated from the posterior predictive distribution.
Additionally, examination of residuals (yn − E[yn |data]) did not reveal strong systematic patterns, further supporting the model’s fit.

3.5

Conclusion

In this chapter, we have detailed a Bayesian linear model incorporating hierarchical and
temporal structures to capture cumulative tire degradation in Formula 1. The latent state

20

Figure 3.1: Forest plot of key parameter estimates from the linear model. The plot shows
the posterior means and 95% credible intervals for the main effects, highlighting which
parameters are most influential and how much uncertainty is present.

Figure 3.2: Estimated cumulative tire degradation (θnstd ) with 95% credible intervals. The
plot shows how the model infers the hidden degradation process over time.

21

Figure 3.3: Trace plots for key parameters of the linear model. Each line represents a
Markov chain for a parameter. Good mixing and lack of trends suggest convergence.

Figure 3.4: Posterior density plots for key parameters of the linear model. Overlapping
densities from different chains indicate good mixing and convergence.

22

Figure 3.5: Posterior predictive check for the lap time model using the linear
degradation formulation. The density of the observed lap times (y) is overlaid with 50
replications from the posterior predictive distribution (y_rep).
process, θn , was modeled not as a simple random walk, but as a dynamic evolution with
a stint-specific mean degradation rate, driver, and compound effects.

23

4.

Bayesian Spline-Based Modeling

This chapter introduces Bayesian Natural Splines for modeling tire degradation, building
on linear models and extending to non-linear, data-driven state-space structures.

4.1

Mathematical Foundations of Spline Smoothing

Splines, specifically B-splines, enable flexible non-linear regression. Given knots Ξ =
{ξ1 < · · · < ξK+d+1 } on [a, b], the B-spline basis {Bk,d (x)}K
k=1 is defined recursively:
Bk,0 (x) = 1[ξk ,ξk+1 ) (x),

Bk,d (x) =

ξk+d+1 − x
x − ξk
Bk,d−1 (x) +
Bk+1,d−1 (x)
ξk+d − ξk
ξk+d+1 − ξk+1

with compact support and partition of unity

∑K

k=1 Bk,d (x) = 1. See [3], [6].

Natural Splines are a type of B-spline with the additional constraint that they are
linear beyond the boundary knots. This often provides more stable and realistic behavior
at the extremes of the data range. In our implementation, the basis for Natural Splines
is generated using the ‘ns()‘ function in R.
The general idea of P-splines [7] involves modeling f (x) =

∑K

k=1 βk Bk (x),

where

smoothness is imposed by penalizing m-th order differences of the coeﬀicients β:
S(β, λ) = ∥y − Bβ∥22 + λ∥Dm β∥22 ,
with closed-form solution:
−1 ⊤
β̂(λ) = (B⊤ B + λD⊤
m Dm ) B y.

The smoothing parameter λ controls the effective degrees of freedom (EDF), given by
trace(H(λ)) where H(λ) is the smoother matrix. Standard selection approaches include
cross-validation or AIC/BIC.
While P-splines achieve smoothness through an explicit penalty term, in our Bayesian
approach using Natural Splines, smoothness is primarily achieved through the prior distribution placed on the spline coeﬀicients βk .

24

4.2

Bayesian Formulation

In a fully Bayesian approach to spline regression, priors are placed on the spline coeﬀicients β and other variance components. For P-splines, the penalty term has a Bayesian
interpretation as a Gaussian prior on the differences of coeﬀicients:
Dm β ∼ N (0, τ 2 I),

λ = σ 2 /τ 2 .

Priors on σ 2 , τ 2 (e.g., inverse-gamma, half-Cauchy) yield a fully Bayesian model [11, 8]. In
our Natural Spline model, we place a prior directly on the coeﬀicients βk . Specifically, we
use βk ∼ N (0, 1), which corresponds to setting σβ2 = 1. This choice provides regularization
to help prevent overfitting while maintaining a relatively simple prior structure for the
spline coeﬀicients.

4.3

State-Space Extension with Spline Drift

We embed Natural Splines in a state-space model. The core idea is that the latent
tire degradation, θn , evolves over time, and this evolution includes a smooth, non-linear
component captured by splines, potentially alongside other systematic drift factors.

4.3.1

Model Structure

The observed standardized lap time is modeled as:
ynstd ∼ Student-t(ν, µdriver[n] + βcompound[n] + θnstd , σ),
with hierarchical priors for the baseline driver effects µdriver and compound adjustments
βcompound similar to those in the linear model (Chapter 3).
The latent degradation process θnstd evolves as follows. It resets to zero at the start of
each new stint or for the first lap overall. For subsequent laps within a stint, its evolution
is:
std
θnstd = θn−1
+ driftspline
+ ηn ,
n

where ηn ∼ N (0, τ 2 ).

The term driftspline
represents the systematic change in degradation at lap n and is defined
n

25

as:
= δdriver[n] + δcompound[n] +
driftspline
n

K
∑

βspline,k Bk (xn ).

k=1

Here, δdriver[n] and δcompound[n] are hierarchical driver and compound-specific drift components, respectively, analogous to those in the linear model (defined with a global mean
drift µδ for drivers and deviations for compounds). The term

∑K

k=1 βspline,k Bk (xn ) is the

contribution from the Natural Spline basis functions Bk (xn ) evaluated at tire life xn ,
with coeﬀicients βspline,k . The random noise ηn is scaled by τ , i.e., ηn = τ zη,n with
zη,n ∼ N (0, 1).
In this formulation, xn represents the tire life at lap n. It is important to note that for
the spline basis functions Bk (xn ) to be effective and numerically stable, the input xn (tire
life) is standardized or normalized before being passed to the basis functions. This often
involves scaling xn to a range like [0, 1] based on the minimum and maximum observed
tire life in the training dataset, or by subtracting the mean and dividing by the standard
deviation. This preprocessing step ensures that the spline knots are appropriately distributed across the effective range of the predictor and improves the conditioning of the
basis matrix.
Priors for βspline,k , variance components, and Student’s t degrees of freedom follow
standard weakly informative choices.

4.4

Stan Implementation

The Stan model includes the spline basis (X_spline), hierarchical parameters, and a
drift term incorporating the spline. The likelihood uses a Student’s t-distribution for
robustness. Priors and transformed parameters reflect the structure above. Posterior
inference is performed via HMC.

4.5

Application to F1 Data

Key preprocessing: standardizing lap times, constructing tire life covariates, encoding
categorical predictors, building the Natural Spline basis matrix X_spline in R using the
‘ns()‘ function.
Model fitting uses Stan, extracting posterior samples for all parameters, including
26

Natural Spline coeﬀicients and latent states. Results are summarized by plotting. The
estimated drift function δ(n) (Figure 4.1) illustrates the inferred rate of degradation over
tire life, complete with uncertainty quantification. Similarly, the evolution of the latent degradation state θnstd is visualized in Figure 4.2, showing the cumulative effect on
performance.
Priors for the hierarchical drift components (e.g., µδ , σδ,driver , σδ,compound ), variance components (σ, τ ), and Student’s t degrees of freedom (ν) follow standard weakly informative choices, similar to those detailed in Chapter 3 and specified in the Stan code (e.g.,
HalfNormal for scales, Exponential for ν).

Figure 4.1: Estimated drift function δ(n) for a representative scenario, showing the mean
posterior estimate and 95% credible bands. This highlights the non-linear nature of the
degradation rate captured by the Natural Spline model.

27

Figure 4.2: Fan chart illustrating the posterior distribution of the cumulative latent degradation θnstd over tire life. The widening bands reflect increasing uncertainty as predictions
extend further into a stint.
Further visualizations include trace and density plots for spline coeﬀicients to assess
MCMC convergence and posterior distributions (e.g., Figure 4.3), and posterior predictive
checks to evaluate model fit (Figure 4.4).

Figure 4.3: Posterior distributions of the Natural Spline basis coeﬀicients (βspline,k ). These
coeﬀicients determine the shape of the estimated drift function.

28

Figure 4.4: Posterior predictive check: scatter plot of observed versus predicted (replicated) lap times. Points clustering around the y=x line indicate good model calibration.

4.6

Diagnostics and Discussion

Diagnostics include:
• MCMC trace/density plots and R̂.
• Posterior predictive checks (observed vs. predicted).
• Visual inspection of residuals and spline drift function.
The estimated drift reveals how tire degradation evolves, highlighting non-linearities
and differences by compound and driver. The Natural Spline-based approach captures
patterns missed by linear models and can inform F1 tire strategy.

4.7

Conclusion

Bayesian Natural Spline state-space models offer a powerful and flexible framework for
capturing the complex, non-linear evolution of tire degradation in Formula 1. By leveraging a data-driven spline basis and Bayesian regularization, these models can adapt to
a wide variety of degradation patterns—capturing subtle features such as initial conditioning, phases of stable wear, and rapid end-of-life drop-offs. The probabilistic nature
of the approach allows for credible interval estimation and principled quantification of
uncertainty, which is crucial for robust inference and interpretation.
29

This methodology enables a detailed reconstruction of latent degradation dynamics,
providing interpretable insights into how tire performance evolves over a stint. The ability to model non-linearities and heterogeneity across drivers and compounds makes the
Natural Spline approach particularly well-suited for the realities of modern motorsport,
where tire behavior is influenced by a multitude of interacting factors. While the model’s
flexibility requires careful regularization and suﬀicient data, its advantages in terms of
expressiveness and uncertainty quantification make it a valuable tool for advanced tire
analysis in racing applications.

30

5.

Conclusion and Future Work

5.1

Comparative Analysis of Tire Degradation Models

This thesis developed and evaluated two distinct Bayesian approaches for modeling Formula 1 tire degradation: a structured linear model (Chapter 3) and a more flexible Natural
Spline based model (Chapter 4). Both aim to provide insights into lap time evolution
due to tire wear, but they differ significantly in their assumptions, flexibility, and interpretability. Here, we compare their key characteristics:
Modeling Approach and Flexibility: The Linear Model employs a state-space
formulation with a relatively rigid structure for the degradation process, a linear drift
or a random walk. This makes it suitable for capturing general trends and monotonic
degradation but less so for complex, non-linear patterns. In contrast, the Natural Spline
model uses a basis of natural spline functions (B-splines with linear behavior beyond
the boundary knots, generated with ‘ns()‘ in R), offering a semi-parametric and highly
flexible approach. It can adapt to non-linear degradation shapes, such as initial grip
improvements followed by rapid drop-offs, by learning the functional form from the data
and leveraging Bayesian regularization on the spline coeﬀicients.
Interpretability: The parameters of the linear model, such as driver-specific baselines or average degradation rates, often have direct and intuitive interpretations. In
the Natural Spline model, on the other hand, individual spline coeﬀicients are not easily
interpretable on their own, but the estimated degradation curve provides a clear visual
representation of the wear pattern, although the overall model complexity is higher.
Predictive Accuracy: The linear model can achieve good predictive accuracy if the
underlying degradation process is indeed close to a linear dynamic or follows the assumed
stochastic process. The Natural Spline model, on the other hand, can offer superior
accuracy when degradation patterns are non-linear, provided it is well regularized (for
example, through appropriate priors) to avoid overfitting. Its data-driven nature allows
it to capture nuances that a fixed-structure model might miss.

31

Computational Eﬀiciency: The linear model is generally less computationally demanding and its simpler structure often leads to faster MCMC convergence. The Natural
Spline model, instead, can be more demanding due to the larger number of parameters
(the spline coeﬀicients) and the need to estimate them.
Data Requirements: Both models benefit from a suﬀicient amount of data. The
linear model can provide reasonable estimates even with moderately sized datasets thanks
to its stronger assumptions. The Natural Spline model, on the other hand, requires more
data to reliably estimate complex shapes and to ensure that the priors effectively prevent
overfitting, especially if many knots (and thus many coeﬀicients) are used.
Uncertainty Quantification: A key strength of both Bayesian approaches is their
intrinsic ability to quantify uncertainty. Both models provide credible intervals for parameter estimates and predictions, offering a probabilistic view of tire degradation.
In summary, the choice between these models involves a trade-off. The linear model
offers simplicity, interpretability, and computational speed, making it suitable for initial
analyses or when degradation is expected to be fairly regular. The Natural Spline model
provides superior flexibility to capture complex realities of tire wear, potentially at the cost
of increased computational resources and a greater need for careful model specification
and validation.

5.2

Future Research Directions

This section discusses potential extensions to the developed tire degradation models,
focusing on enhancing model flexibility, predictive power, and real-time applicability. Key
directions include more expressive nonparametric models like Gaussian Processes (GPs)
and advanced sequential inference techniques such as Particle Filters (PF).

5.2.1

Gaussian Processes for Enhanced Degradation Modeling

A highly promising direction is to replace or augment the spline-based or linear degradation components with a Gaussian Process (GP) prior [12]. GPs offer a flexible Bayesian
nonparametric approach, treating the degradation trajectory itself as a random function. The prior is specified by a mean function and a covariance kernel k(n, n′ ), which
encodes assumptions about the degradation trajectory’s smoothness, length-scale, and
32

other structural properties. This nonparametric flexibility allows GPs to capture complex,
highly non-linear wear patterns that might be challenging for parametric or fixed-basis
approaches. The marginal likelihood in GPs naturally balances model fit and complexity,
aiding in hyperparameter learning.
Key extensions and considerations for GP-based degradation modeling include:
• Hierarchical GPs: To account for multi-level data structures (e.g., different
drivers, tire compounds, tracks), hierarchical GP models can be employed. These
models allow individual degradation curves for each context while sharing statistical strength through common hyperpriors on covariance parameters, improving
estimates in data-sparse scenarios.
• Sparse GP Approximations: Standard GP inference scales as O(T 3 ) with T
observations. For larger datasets (e.g., high-frequency telemetry or many stints),
sparse GP approximations (e.g., FITC, variational inducing points) reduce complexity, often to O(T m2 ) for m ≪ T inducing points, making GPs scalable [12].
This is crucial for handling large data volumes or for real-time updates.
Adopting GPs could significantly improve the model’s ability to adapt to nuanced degradation patterns while maintaining a fully probabilistic Bayesian interpretation.

5.2.2

Particle Filters (Sequential Monte Carlo) for Online Inference

To transition from offline analysis to real-time decision support, Sequential Monte Carlo
(SMC) methods, also known as Particle Filters (PF), are essential [1, 4]. SMC methods
perform Bayesian inference on state-space models as new observations arrive lap-by-lap.
A state-space model for tire degradation would define a latent state xk (degradation level
at lap k), a state transition model p(xk | xk−1 ), and an observation model p(yk | xk )
linking the state to data yk (e.g., lap time). SMC approximates the evolving posterior
p(xk | y1:k ) using a set of weighted samples (particles). The particles are propagated
(predicted), weighted by the likelihood of the new observation, and resampled. This cycle
provides a continually updated estimate of the tire’s degradation state. Particle filters can
handle non-linear and non-Gaussian models, crucial for realistic degradation dynamics.
This capability would enable live tracking of tire condition, informing strategic decisions
33

like pit stops. Challenges include computational cost for real-time updates and potential
particle degeneracy, requiring eﬀicient implementation and careful model design.

5.2.3

Other Promising Directions

Beyond GPs and PFs, other enhancements could include:
• Multivariate State Modeling with Telemetry Features: Integrating diverse
telemetry data (tire temperatures, pressures, g-forces) into a multivariate statespace model or as covariates. This could involve a latent state vector capturing not
just ”degradation” but also related factors like thermal state, with a joint likelihood
for multiple data streams (lap times, temperatures). This holistic approach could
lead to more accurate and robust inference of tire health by capturing the interplay
between various physical factors.
• Dynamic Model Parameters: Allowing key model parameters (e.g., degradation
rates, noise levels, or even GP kernel parameters) to vary over time or according to
changing track conditions or driving styles.

5.3

Conclusion

The methodological avenues outlined—enhancing model flexibility with GPs, enabling
real-time inference via Particle Filters, and broadening scope by incorporating more data
sources—each target specific aspects of the tire degradation modeling problem. In combination, these advances could substantially elevate the fidelity and practicality of the
models. For example, a hierarchical sparse GP model could learn generalizable degradation patterns across races, while a particle filtering system could use those patterns to
swiftly adapt predictions during an ongoing race.
The ultimate implication for in-race strategy is significant: teams would be empowered
with more accurate and up-to-date probabilistic estimates of tire health. This means
better timing of pit stops (avoiding both untimely tire failures and overly conservative
early stops), more informed tire compound choices under evolving conditions, and the
ability to anticipate performance cliff points with greater confidence.
This thesis has demonstrated the value of Bayesian statistical modeling in dissecting
the complex problem of tire degradation in motorsport. The comparison between the
34

linear and Natural Spline models highlights the trade-offs between structural simplicity
and adaptive flexibility. By pursuing the future research directions discussed, particularly
Gaussian Processes and Sequential Monte Carlo methods, the gap between off-line statistical analysis and on-line, actionable decision support can be effectively bridged. This
will provide Formula 1 teams with an increasingly powerful Bayesian toolkit to navigate
the ever-critical challenge of tire management, ultimately sharpening their competitive
edge.

35

Bibliography
[1] M Sanjeev Arulampalam, Simon Maskell, Neil Gordon, and Tim Clapp. A tutorial on particle filters for online nonlinear/non-gaussian bayesian tracking. IEEE
Transactions on Signal Processing, 50(2):174–188, 2002.
[2] Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich,
Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell.
Stan: A probabilistic programming language. Journal of statistical software, 76(1):1–
32, 2017.
[3] Carl de Boor. A Practical Guide to Splines, volume 27 of Applied Mathematical
Sciences. Springer-Verlag, revised edition, 2001.
[4] Arnaud Doucet and Adam M Johansen. A tutorial on particle filtering and smoothing: Fifteen years later. Handbook of nonlinear filtering, 12(656–704), 2009.
[5] James Durbin and Siem Jan Koopman. Time Series Analysis by State Space Methods.
Oxford University Press, 2nd edition, 2012.
[6] Paul H. C. Eilers and Brian D. Marx. Practical Smoothing: The Joys of P-splines.
Cambridge University Press, 2021.
[7] Paul HC Eilers and Brian D Marx. Flexible smoothing with b-splines and penalties.
Statistical Science, 11(2):89–121, 1996.
[8] Ludwig Fahrmeir, Thomas Kneib, Stefan Lang, and Brian Marx. Regression: Models,
Methods and Applications. Springer Science & Business Media, 2013.
[9] Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and
Donald B Rubin. Bayesian Data Analysis. CRC Press, 3rd edition, 2013.
[10] Rudolf E Kalman. A new approach to linear filtering and prediction problems. Journal of Basic Engineering, 82(1):35–45, 1960.
[11] Sergei Lang and Andreas Brezger. Bayesian p-splines. Journal of Computational and
Graphical Statistics, 13(1):183–212, 2004.
36

[12] Carl Edward Rasmussen and Christopher K I Williams. Gaussian Processes for
Machine Learning. MIT Press, 2006.
[13] Christian P Robert. The Bayesian Choice: From Decision-Theoretic Foundations
to Computational Implementation. Springer Science & Business Media, 2nd edition,
2007.
[14] Andrea Stella. Stella on mclaren’s mastery of tyre management after f1 miami gp.
Pit Debrief, 2024. Accessed: June 16, 2024.
[15] FastF1 Development Team. Fastf1: A python library for formula 1 data analysis,
2023.
[16] Aki Vehtari, Andrew Gelman, and Jonah Gabry. Practical bayesian model evaluation
using leave-one-out cross-validation and waic. Statistics and Computing, 27(5):1413–
1432, 2017.

37

